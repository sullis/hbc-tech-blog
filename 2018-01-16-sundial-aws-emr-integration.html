<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Sundial AWS EMR Integration</title><title>Sundial AWS EMR Integration | HBC Tech</title><meta property="og:title" content="Sundial AWS EMR Integration"><meta name="author" content="Giovanni Gargiulo"><meta property="og:locale" content="en_US"><meta name="description" content="AWS Elastic Map Reduce on Sundial"><meta property="og:description" content="AWS Elastic Map Reduce on Sundial"><link rel="canonical" href="https://saksdirect.github.io/hbc-tech-blog/2018-01-16-sundial-aws-emr-integration.html"><meta property="og:url" content="https://saksdirect.github.io/hbc-tech-blog/2018-01-16-sundial-aws-emr-integration.html"><meta property="og:site_name" content="HBC Tech"><meta property="og:type" content="article"><meta property="article:published_time" content="2018-01-16T00:00:00-05:00"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@"><meta name="twitter:creator" content="@Giovanni Gargiulo"><script type="application/ld+json">{"name":null,"description":"AWS Elastic Map Reduce on Sundial","author":{"@type":"Person","name":"Giovanni Gargiulo"},"@type":"BlogPosting","url":"https://saksdirect.github.io/hbc-tech-blog/2018-01-16-sundial-aws-emr-integration.html","publisher":null,"image":null,"headline":"Sundial AWS EMR Integration","dateModified":"2018-01-16T00:00:00-05:00","datePublished":"2018-01-16T00:00:00-05:00","sameAs":null,"mainEntityOfPage":{"@type":"WebPage","@id":"https://saksdirect.github.io/hbc-tech-blog/2018-01-16-sundial-aws-emr-integration.html"},"@context":"http://schema.org"}</script><link rel="stylesheet" href="https://saksdirect.github.io/hbc-tech-blog/assets/css/main.css"><link rel="canonical" href="https://saksdirect.github.io/hbc-tech-blog/2018-01-16-sundial-aws-emr-integration.html"><link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,700" rel="stylesheet"><link rel="shortcut icon" href="https://saksdirect.github.io/hbc-tech-blog/assets/images/favicon.ico"></head><body aria-label="Content"><header id="site-header" class="site-header"><div class="site-header__inner"><a class="site-header__logo" href="https://saksdirect.github.io/hbc-tech-blog/"><svg class="hbc-tech-logo" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 64 52"><use class="hbc-tech-logo__text" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#hbc-tech-logo"></use></svg></a><nav id="menu" class="navigation"><svg class="navigation__menu-icon" xmlns="http://www.w3.org/2000/svg"><path class="bar bar__top" d="M0,3 L30,3"></path><path class="bar bar__cross-1" d="M0,14 L30,14"></path><path class="bar bar__cross-2" d="M0,14 L30,14"></path><path class="bar bar__bottom" d="M0,25 L30,25"></path></svg><menu class="menu"><ul class="link-list"><li class="link-list__link-item"><a href="https://saksdirect.github.io/hbc-tech-blog/" class="link-list__link"><span class="link-list__link-highlight">Insights</span></a></li><li class="link-list__link-item"><a href="https://saksdirect.github.io/hbc-tech-blog/code" class="link-list__link"><span class="link-list__link-highlight">Code</span></a></li><li class="link-list__link-item"><a href="https://saksdirect.github.io/hbc-tech-blog/about" class="link-list__link"><span class="link-list__link-highlight">About</span></a></li><li class="link-list__link-item"><a href="https://saksdirect.github.io/hbc-tech-blog/work-here" class="link-list__link"><span class="link-list__link-highlight">Work Here</span></a></li></ul></menu></nav><search id="header-search" class="header-search"><form class="header-search__form"><input type="text" class="header-search__input" id="header-search-input" placeholder="Search" name="query"></form><svg id="header-search__toggle" class="header-search__svg" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 64 52"><use class="header-search__icon" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#search"></use></svg><section class="header-search__results" id="header-search__results"></section></search></div></header><section class="content"><article class="article"><header class="article__header article__header--reveal"><h1 class="header-title" title="Sundial AWS EMR Integration">Sundial AWS EMR Integration</h1><span id="no-image-placeholder" class="no-image-placeholder"></span><div class="article-meta"><a href="https://saksdirect.github.io/hbc-tech-blog/categories/#aws" class="article-meta__category">aws</a> <span class="slug-divider"></span> <span class="article-meta__author">Giovanni Gargiulo</span> <span class="slug-divider"></span> <span class="article-meta__date">JAN 16, 2018</span></div></header><section class="article__content article__content--reveal"><div class="article__content__read-time"><span class="read-time" title="Estimated read time"><span class="read-time__text-1">12 min</span> <span class="read-time__text-2">Read</span> <span class="read-time__text-3">Time</span></span></div><div class="article__content__share-buttons"><ul class="share-buttons"><li class="share-buttons__link-item"><a href="https://twitter.com/intent/tweet?text=https://saksdirect.github.io/hbc-tech-blog//2018-01-16-sundial-aws-emr-integration.html" class="share-buttons__link" title="Share on Twitter" target="_blank"><svg class="hbc-svg-icon" height="36" width="36" xmlns="http://www.w3.org/2000/svg"><use class="hbc-svg-icon--twitter" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#twitter"></use></svg></a></li><li class="share-buttons__link-item"><a href="https://www.linkedin.com/shareArticle?mini=true&url=https://saksdirect.github.io/hbc-tech-blog/&source=/2018-01-16-sundial-aws-emr-integration.html&title=Sundial AWS EMR Integration" class="share-buttons__link" title="Share on Linkedin" target="_blank"><svg height="36" width="36" xmlns="http://www.w3.org/2000/svg"><use class="hbc-svg-icon" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#linkedin"></use></svg></a></li><li class="share-buttons__link-item"><a href="https://www.facebook.com/sharer/sharer.php?u=https://saksdirect.github.io/hbc-tech-blog//2018-01-16-sundial-aws-emr-integration.html" class="share-buttons__link" title="Share on Facebook" target="_blank"><svg height="36" width="36" xmlns="http://www.w3.org/2000/svg"><use class="hbc-svg-icon" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#facebook"></use></svg></a></li><li class="share-buttons__link-item"><a href="https://www.reddit.com/submit?url=https://saksdirect.github.io/hbc-tech-blog//2018-01-16-sundial-aws-emr-integration.html" class="share-buttons__link" title="Share on Reddit" target="_blank"><svg height="36" width="36" xmlns="http://www.w3.org/2000/svg"><use class="hbc-svg-icon" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#reddit"></use></svg></a></li></ul></div><div class="article__content__body"><h1 id="aws-elastic-map-reduce-on-sundial">AWS Elastic Map Reduce on Sundial</h1><p>Today I want to talk about a recent improvement we implemented in <a href="https://github.com/gilt/sundial">Sundial</a>, an Open Source product launched by Gilt in early 2016. With <a href="https://github.com/gilt/sundial/releases/tag/v2.0.0">Sundial 2.0.0</a> it’s now possible to schedule AWS Elastic Map Reduce jobs.</p><p>For those of you who are not familiar with it, <a href="https://github.com/gilt/sundial">Sundial</a> is a batch job scheduler, developed by the Gilt Personalization Team, that works with Amazon ECS and Amazon Batch.</p><p>Before jumping into the nitty gritty details, it’s worth taking a deeper dive into the current batch job processing setup in Gilt and the challenges we have recently started to face.</p><p>We will quickly cover the following areas:</p><ul><li>the current batch jobs setup</li><li>batch job scalability</li></ul><h2 id="batch-processing-today">Batch processing today</h2><p>Every night, the Gilt Aster data warehouse (DW) is locked down in order to update it with the latest data coming from the relevant area of the business. During this lock, Extract-Transform-Load (<a href="https://www.webopedia.com/TERM/E/ETL.html">ETL</a>) suites, or <a href="https://www.ironsidegroup.com/2015/03/01/_ETL_-vs-elt-whats-the-big-difference/">ELT as we prefer to call it</a>, are run. When all the jobs complete, the DW gets unlocked and the normal access to Aster is resumed. There are a number of client systems relying on the DW, most relevant are BI tools, i.e <a href="https://looker.com/">Looker</a>, and Sundial. Sundial in particular is used in personalization for scheduling additional jobs and to build Machine Learning models. Since there is no synchronization between Aster and Sundial, occasionally when Aster takes longer to complete, Sundial jobs would fail because of the DW being still locked down or data being stale.</p><h2 id="performance-degradation">Performance degradation</h2><p>Because Aster is a shared resource, and the number of jobs relying on it is increasing day by day, in the past few weeks we’ve experienced significant performance degradation. This issue is particularly amplified at a specific time of the week, when BI reports are generated. The result is that batch jobs and reports are taking longer and longer to complete. This of course affects developers experience and productivity.</p><h2 id="emr-adoption">EMR adoption</h2><p>Because of all the nuisances above, there is additional operational time spent to restart failed jobs. Furthermore, when developing a new model, most of the time is spent extracting and massaging data, rather than focusing on the actual job logic.</p><p>It’s easy to understand that Aster wasn’t a good candidate anymore for us and that we needed to migrate to a better and more <a href="https://en.wikipedia.org/wiki/Elasticity_(cloud_computing)">elastic</a> platform.</p><p>The solution we were looking for should:</p><ul><li>work with multiple data formats</li><li>be scalable</li><li>be owned by the team</li><li>be easy to integrate with our scheduling solution</li></ul><p>We didn’t have to look far to find a great candidate to solve our problems: Spark running on <a href="https://aws.amazon.com/emr/">AWS EMR (Elastic Map Reduce)</a>. Amazon EMR provides a managed Hadoop framework that makes it easy, fast, and cost-effective to process vast amounts of data across dynamically scalable Amazon EC2 instances. You can also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and Flink in Amazon EMR, and interact with data in other AWS data stores such as Amazon S3 and Amazon DynamoDB.</p><p>A complete list of open source applications (or components) running on AWS ERM can be found <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html">here</a>.</p><p>AWS EMR also offers a nice SDK to spin a new dynamic EMR cluster, run a job and tear down resources <em>on the fly</em> and a cost per second billing system so to make the whole platform very cost efficient.</p><p>The last two perks of using AWS EMR are:</p><ul><li><a href="https://aws.amazon.com/ec2/spot/">AWS Spot Instances</a>: running hardware at a discounted price</li><li><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-supported-instance-types.html">Large variety of hardware</a>: most of ELT jobs run on commodity hardware, some ML require intensive GPU computation and EMR offers hardware solutions for all of our use cases.</li></ul><h2 id="the-sundial-emr-integration">The Sundial EMR Integration</h2><p>Since we were already using Sundial for most of our ETL and ML heavy lifting, we decided to extend the Sundial <code class="highlighter-rouge">task_definition</code> and add a new <code class="highlighter-rouge">executable</code>: the <code class="highlighter-rouge">emr_command</code>.</p><p>Features we’ve implemented are:</p><ul><li>running a Spark EMR job on a pre-existing cluster</li><li>running a Spark EMR job on a new created-on-the-fly cluster (and automatic tear down of resources)</li><li>choose between <code class="highlighter-rouge">on_demand</code> vs <code class="highlighter-rouge">spot</code> instances</li><li>live logs</li></ul><p>In the next two paragraphs I will go through two Sundial EMR task definition examples: the first is a Spark EMR job running on a pre-existing cluster, the second is the same job but running on a dynamically created cluster instead.</p><h3 id="running-a-job-on-a-pre-existing-emr-cluster">Running a job on a pre-existing EMR Cluster</h3><p>Launching an EMR job on a pre-existing cluster is really simple, all that you need are some job details and the <code class="highlighter-rouge">cluster_id</code> where you want the job to run.</p><div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="w"> </span><span class="s2">"executable"</span><span class="err">:</span><span class="p">{</span><span class="w">
    </span><span class="nt">"emr_command"</span><span class="p">:{</span><span class="w">
       </span><span class="nt">"emr_cluster"</span><span class="p">:{</span><span class="w">
          </span><span class="nt">"existing_emr_cluster"</span><span class="p">:{</span><span class="w">
             </span><span class="nt">"cluster_id"</span><span class="p">:</span><span class="s2">"j-123ABC456DEF9"</span><span class="w">
          </span><span class="p">}</span><span class="w">
       </span><span class="p">},</span><span class="w">
       </span><span class="nt">"job_name"</span><span class="p">:</span><span class="s2">"MyJobName1"</span><span class="p">,</span><span class="w">
       </span><span class="nt">"region"</span><span class="p">:</span><span class="s2">"us-east-1"</span><span class="p">,</span><span class="w">
       </span><span class="nt">"class"</span><span class="p">:</span><span class="s2">"com.company.job.spark.core.MainClass"</span><span class="p">,</span><span class="w">
       </span><span class="nt">"s3_jar_path"</span><span class="p">:</span><span class="s2">"s3://my-spark-job-release-bucket/my-job-spark-v1-0-0.jar"</span><span class="p">,</span><span class="w">
       </span><span class="nt">"spark_conf"</span><span class="p">:[</span><span class="w">
          </span><span class="s2">"spark.driver.extraJavaOptions=-Denvironment=production"</span><span class="w">
       </span><span class="p">],</span><span class="w">
       </span><span class="nt">"args"</span><span class="p">:[</span><span class="w">
          </span><span class="s2">"arg1"</span><span class="p">,</span><span class="w"> </span><span class="s2">"arg2"</span><span class="w">
       </span><span class="p">],</span><span class="w">
       </span><span class="nt">"s3_log_details"</span><span class="p">:{</span><span class="w">
          </span><span class="nt">"log_group_name"</span><span class="p">:</span><span class="s2">"spark-emr-log-group"</span><span class="p">,</span><span class="w">
          </span><span class="nt">"log_stream_name"</span><span class="p">:</span><span class="s2">"spark-emr-log-stream"</span><span class="w">
       </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
 </span><span class="p">}</span><span class="w">
</span></code></pre></div><p>The other properties are:</p><ul><li><em>class</em>: the fully qualified main class of the job, e.g. “com.company.job.spark.core.MainClass”</li><li><em>s3_jar_path</em>: the s3 path to the job jar file e.g “s3://my-spark-job-release-bucket/my-job-spark-v1-0-0.jar”</li><li><em>spark_conf</em>: this is a <strong>list</strong> of attributes that you can pass to the spark driver, like memory or Java Opts (as per above example)</li><li><em>args</em>: another list of params that will be passed to the <strong>MainClass</strong> as arguments (as per above example)</li><li><em>s3_log_details</em>: Cloudwatch Log Group and Stream names for your job. See <a href="#emr-logs">EMR Logs paragraph</a></li></ul><h4 id="emr-logs">EMR Logs</h4><p>One nice feature of Sundial is the possibility of viewing jobs’ live logs. While AWS Elastic Container Service (ECS) and Batch natively offer a way to access live logs, EMR updates logs only every five minutes on S3 and it cannot be used as feed for live logs. Since there isn’t a straightforward way of fixing this, it is developer’s responsibility to implement the code that streams job’s log to <a href="https://aws.amazon.com/cloudwatch/">AWS Cloudwatch Logs</a>. One way of achieving this is via the <a href="https://github.com/speedwing/log4j-cloudwatch-appender">log4j-cloudwatch-appender</a>.</p><p>The downside of having jobs running on <em>static</em> AWS EMR clusters is that you will be paying for it even if no jobs are running. For this reason it would be ideal if we could spin up an EMR cluster <em>on-the-fly</em>, run a Spark job and then dispose all the resources.</p><p>If you want to know more, well, keep reading!</p><h3 id="running-a-job-on-a-dynamic-emr-cluster">Running a job on a dynamic EMR Cluster</h3><p>The Sundial Task definition that uses a dynamic cluster is fairly more complex and gives you some fine grained control when provisioning your cluster. At the same time though, if your jobs don’t require very specific configurations (e.g. permissions, aws market type), sensible default options have been provided so to simplify the Task Definition where possible.</p><p>Let’s dig into the different sections of the json template.</p><div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="s2">"emr_cluster"</span><span class="err">:</span><span class="p">{</span><span class="w">
  </span><span class="nt">"new_emr_cluster"</span><span class="p">:{</span><span class="w">
     </span><span class="nt">"name"</span><span class="p">:</span><span class="s2">"My Cluster Name"</span><span class="p">,</span><span class="w">
     </span><span class="nt">"release_label"</span><span class="p">:</span><span class="s2">"emr-5.11.0"</span><span class="p">,</span><span class="w">
     </span><span class="nt">"applications"</span><span class="p">:[</span><span class="w">
        </span><span class="s2">"Spark"</span><span class="w">
     </span><span class="p">],</span><span class="w">
     </span><span class="nt">"s3_log_uri"</span><span class="p">:</span><span class="s2">"s3://cluster-log-bucket"</span><span class="p">,</span><span class="w">
     </span><span class="nt">"master_instance"</span><span class="p">:{</span><span class="w">
        </span><span class="nt">"emr_instance_type"</span><span class="p">:</span><span class="s2">"m4.large"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"instance_count"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="w">
        </span><span class="nt">"aws_market"</span><span class="p">:{</span><span class="w">
           </span><span class="nt">"on_demand"</span><span class="p">:</span><span class="s2">"on_demand"</span><span class="w">
        </span><span class="p">}</span><span class="w">
     </span><span class="p">},</span><span class="w">
     </span><span class="nt">"core_instance"</span><span class="p">:{</span><span class="w">
        </span><span class="nt">"emr_instance_type"</span><span class="p">:</span><span class="s2">"m4.xlarge"</span><span class="p">,</span><span class="w">
        </span><span class="nt">"instance_count"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="w">
        </span><span class="nt">"aws_market"</span><span class="p">:{</span><span class="w">
           </span><span class="nt">"on_demand"</span><span class="p">:</span><span class="s2">"on_demand"</span><span class="w">
        </span><span class="p">}</span><span class="w">
     </span><span class="p">},</span><span class="w">
     </span><span class="nt">"emr_service_role"</span><span class="p">:{</span><span class="w">
        </span><span class="nt">"default_emr_service_role"</span><span class="p">:</span><span class="s2">"EMR_DefaultRole"</span><span class="w">
     </span><span class="p">},</span><span class="w">
    </span><span class="nt">"emr_job_flow_role"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nt">"default_emr_job_flow_role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"EMR_EC2_DefaultRole"</span><span class="w">
    </span><span class="p">},</span><span class="w">
     </span><span class="nt">"ec2_subnet"</span><span class="p">:</span><span class="s2">"subnet-a123456b"</span><span class="p">,</span><span class="w">
     </span><span class="nt">"visible_to_all_users"</span><span class="p">:</span><span class="kc">true</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div><p>The json object name for a <em>dynamic emr cluster</em> is <code class="highlighter-rouge">new_emr_cluster</code>. It is composed by the following attributes:</p><ul><li><em>name</em>: The name that will appear on the AWS EMR console</li><li><em>release_label</em>: The EMR version of the cluster to create. Each EMR version maps to specific version of the applications that can run in the EMR cluster. Additional details are available on the <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html">AWS EMR components page</a></li><li><em>applications</em>: The list of applications to launch on the cluster. For a comprehensive list of available applications, visit the <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html">AWS EMR components page</a></li><li><em>s3_log_uri</em>: The s3 bucket where the EMR cluster put their log files. These are both cluster logs as well as <code class="highlighter-rouge">stdout</code> and <code class="highlighter-rouge">stderr</code> of the EMR job</li><li><em>master_instance</em>: The master node hardware details (see below for more details.)</li><li><em>core_instance</em>: The core node hardware details (see below for more details.)</li><li><em>task_instance</em>: The task node hardware details (see below for more details.)</li><li><em>emr_service_role</em>: The IAM role that Amazon EMR assumes to access AWS resources on your behalf. For more information, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-iam-roles.html">Configure IAM Roles for Amazon EMR</a></li><li><em>emr_job_flow_role</em>: (Also called instance profile and EC2 role.) Accepts an instance profile that’s associated with the role that you want to use. All EC2 instances in the cluster assume this role. For more information, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html">Create and Use IAM Roles for Amazon EMR</a> in the Amazon EMR Management Guide</li><li><em>ec2_subnet</em>: The subnet where to spin the EMR cluster. (Optional if the account has only the standard VPC)</li><li><em>visible_to_all_users</em>: Indicates whether the instances in the cluster are visible to all IAM users in the AWS account. If you specify true, all IAM users can view and (if they have permissions) manage the instances. If you specify false, only the IAM user that created the cluster can view and manage it</li></ul><h4 id="master-core-and-task-instances">Master, core and task instances</h4><p>An EMR cluster is composed by exactly one master instance, at least one core instance and any number of tasks instances.</p><p>A detailed explanation of the different instance types is available in the <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances.html">AWS EMR plan instances page</a>.</p><p>For simplicity I’ll paste a snippet of the AWS official documentation:</p><blockquote><ul><li>master node: The master node manages the cluster and typically runs master components of distributed applications. For example, the master node runs the YARN ResourceManager service to manage resources for applications, as well as the HDFS NameNode service. It also tracks the status of jobs submitted to the cluster and monitors the health of the instance groups. Because there is only one master node, the instance group or instance fleet consists of a single EC2 instance.</li><li>core node: Core nodes are managed by the master node. Core nodes run the Data Node daemon to coordinate data storage as part of the Hadoop Distributed File System (HDFS). They also run the Task Tracker daemon and perform other parallel computation tasks on data that installed applications require.</li><li>task node: Task nodes are optional. You can use them to add power to perform parallel computation tasks on data, such as Hadoop MapReduce tasks and Spark executors. Task nodes don’t run the Data Node daemon, nor do they store data in HDFS.</li></ul></blockquote><p>The json below describes configuration details of an EMR master instance:</p><div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="w"> </span><span class="s2">"master_instance"</span><span class="err">:</span><span class="p">{</span><span class="w">
    </span><span class="nt">"emr_instance_type"</span><span class="p">:</span><span class="s2">"m4.large"</span><span class="p">,</span><span class="w">
    </span><span class="nt">"instance_count"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="w">
    </span><span class="nt">"aws_market"</span><span class="p">:{</span><span class="w">
       </span><span class="nt">"on_demand"</span><span class="p">:</span><span class="s2">"on_demand"</span><span class="w">
    </span><span class="p">}</span><span class="w">
 </span><span class="p">}</span><span class="err">,</span><span class="w">
</span></code></pre></div><p>Please note that there can only be exactly one master node, if a different values is specified in the <code class="highlighter-rouge">instance_count</code>, it is ignored. For other instance group types the value <code class="highlighter-rouge">instance_count</code> represents, as the name says, the number of EC2 instances to launch for that instance type.</p><p>Other attributes are:</p><ul><li><em>emr_instance_type</em>: the EC2 instance type to use when launching the EMR instance</li><li><em>aws_market</em>: the marketplace to provision instances for this group. It can be either <code class="highlighter-rouge">on_demand</code> or <code class="highlighter-rouge">spot</code></li></ul><p>An example of a EMR instance using spot is:</p><div class="language-json highlighter-rouge"><pre class="highlight"><code><span class="s2">"aws_market"</span><span class="err">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nt">"spot"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nt">"bid_price"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.07</span><span class="w">
    </span><span class="p">}</span><span class="w">
 </span><span class="p">}</span><span class="w">
</span></code></pre></div><p>Where <code class="highlighter-rouge">bid_price</code> is the Spot bid price in dollars.</p><h2 id="limitations">Limitations</h2><p>Because of some AWS EMR implementation details, Sundial has two major limitations when it comes to EMR job scheduling.</p><p>The first limitation is that Sundial is not able to stop EMR jobs running on pre-existing clusters. Since jobs on the EMR cluster are scheduled via <code class="highlighter-rouge">yarn</code> and since AWS did not build any api on top of it, once a job is scheduled on an existing EMR cluster, in order to kill it, it would be required to ssh on the EC2 instance where the master node is running, query <code class="highlighter-rouge">yarn</code> so to find out the correct application id and issue a yarn kill command. We decided to not implement this feature because it would have greatly over complicated the job definition. Jobs running on dynamic cluster are affected by the same issue. We’ve managed to still implement this feature by simply killing the whole EMR cluster.</p><p>The second limitation is about live logs. As previously mentioned live logs are not implemented out of the box. Developers require to stream logs to Cloudwatch Logs and set log group and log name in the task definition.</p></div><footer class="article__content__footer"><div class="article-tags"><span class="article-tags__tag">aws</span><span>,</span> <span class="article-tags__tag">data</span><span>,</span> <span class="article-tags__tag">sundial</span><span>,</span> <span class="article-tags__tag">etl</span><span>,</span> <span class="article-tags__tag">scheduling</span><span>,</span> <span class="article-tags__tag">machine learning</span></div><section class="author-bio"><svg class="author-bio__avatar" height="36" width="36" xmlns="http://www.w3.org/2000/svg"><use class="hbc-svg-icon hbc-svg-icon--avatar__circle" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#circle"></use><use class="hbc-svg-icon hbc-svg-icon--avatar__head" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#head"></use><use class="hbc-svg-icon hbc-svg-icon--avatar__body" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#body"></use></svg><span class="author-bio__name">Giovanni Gargiulo</span></section></footer></section><aside class="recirc"><h2 class="header__title">Recent Insights</h2><span class="slug-divider"></span> <a class="header__view-all-link" href="https://saksdirect.github.io/hbc-tech-blog/categories/index.html">See All</a><div class="recirc__articles"><article class="recirc__articles__item"><section class="snippet"><h1 class="snippet__title"><a href="https://saksdirect.github.io/hbc-tech-blog/2017-02-06-sundial-pagerduty-integration.html" class="snippet__title__link" title="Sundial PagerDuty Integration">Sundial PagerDuty Integration</a></h1><div class="snippet__meta"><a class="meta__category-link" href="https://saksdirect.github.io/hbc-tech-blog/category/infrastructure">infrastructure</a> <span class="slug-divider"></span> <span class="meta__author">Giovanni Gargiulo</span> <span class="slug-divider"></span> <span class="meta__date">FEB 6, 2017</span></div><a href="https://saksdirect.github.io/hbc-tech-blog/2017-02-06-sundial-pagerduty-integration.html" class="snippet__excerpt__link" title="Sundial PagerDuty Integration"><p class="snippet__excerpt">Sundial</p></a></section></article><article class="recirc__articles__item"><section class="snippet"><h1 class="snippet__title"><a href="https://saksdirect.github.io/hbc-tech-blog/2018-01-03-instant-voucher-serverless.html" class="snippet__title__link" title="Revitalize Gilt City's Order Processing with Serverless Architecture">Revitalize Gilt City's Order Processing with Serverless Architecture</a></h1><div class="snippet__meta"><a class="meta__category-link" href="https://saksdirect.github.io/hbc-tech-blog/categories/#aws">aws</a> <span class="slug-divider"></span> <span class="meta__author">Liyu Ma</span> <span class="slug-divider"></span> <span class="meta__date">JAN 3, 2018</span></div><a href="https://saksdirect.github.io/hbc-tech-blog/2018-01-03-instant-voucher-serverless.html" class="snippet__excerpt__link" title="Revitalize Gilt City's Order Processing with Serverless Architecture"><p class="snippet__excerpt">Instant Vouchers Initiative</p></a></section></article><article class="recirc__articles__item"><section class="snippet"><h1 class="snippet__title"><a href="https://saksdirect.github.io/hbc-tech-blog/2015-04-16-tips-for-debugging-ec2-container-service.html" class="snippet__title__link" title="Tips for Debugging EC2 Container Service">Tips for Debugging EC2 Container Service</a></h1><div class="snippet__meta"><a class="meta__category-link" href="https://saksdirect.github.io/hbc-tech-blog/categories/#aws">aws</a> <span class="slug-divider"></span> <span class="meta__author">Scott Thompson</span> <span class="slug-divider"></span> <span class="meta__date">APR 16, 2015</span></div><a href="https://saksdirect.github.io/hbc-tech-blog/2015-04-16-tips-for-debugging-ec2-container-service.html" class="snippet__excerpt__link" title="Tips for Debugging EC2 Container Service"><p class="snippet__excerpt">Last week, Amazon made their Elastic Container Service generally available and also released a web UI to make it easier to create tasks. This service was exciting for our personalization team as we wanted to leverage ECS to simplify deployment of our jobs and have better control over failures.Getting started with ECS is easy but requires your full attention because there are a lot of important details (did you remember to...</p></a></section></article><article class="recirc__articles__item"><section class="snippet"><h1 class="snippet__title"><a href="https://saksdirect.github.io/hbc-tech-blog/2018-01-03-instant-voucher-serverless.html" class="snippet__title__link" title="Revitalize Gilt City's Order Processing with Serverless Architecture">Revitalize Gilt City's Order Processing with Serverless Architecture</a></h1><div class="snippet__meta"><a class="meta__category-link" href="https://saksdirect.github.io/hbc-tech-blog/categories/#aws">aws</a> <span class="slug-divider"></span> <span class="meta__author">Liyu Ma</span> <span class="slug-divider"></span> <span class="meta__date">JAN 3, 2018</span></div><a href="https://saksdirect.github.io/hbc-tech-blog/2018-01-03-instant-voucher-serverless.html" class="snippet__excerpt__link" title="Revitalize Gilt City's Order Processing with Serverless Architecture"><p class="snippet__excerpt">Instant Vouchers Initiative</p></a></section></article></div></aside></article></section><footer class="footer"><svg class="est1670" xmlns="http://www.w3.org/2000/svg"><use class="hbc-tech-logo__use" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#est1670"></use></svg><section class="footer__links"><ul class="social-links social-links__list"><li class="social-links__list-item"><a class="social-links__link" target="_blank" rel="next" href="https://www.linkedin.com/company/hbc_digital/"><svg class="social-links__icon" xmlns="http://www.w3.org/2000/svg"><use class="linkedin" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#linkedin"></use></svg></a></li><li class="social-links__list-item"><a class="social-links__link" target="_blank" rel="next" href="https://twitter.com/hbcdigital/"><svg class="social-links__icon" xmlns="http://www.w3.org/2000/svg"><use class="twitter" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#twitter"></use></svg></a></li><li class="social-links__list-item"><a class="social-links__link" target="_blank" rel="next" href="https://www.instagram.com/hbcdigital"><svg class="social-links__icon" xmlns="http://www.w3.org/2000/svg"><use class="instagram" xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://saksdirect.github.io/hbc-tech-blog/assets/images/hbc-icons.svg#instagram"></use></svg></a></li></ul><p class="copyright">&copy; 2018 HBC Tech</p></section></footer><script type="text/javascript" src="https://saksdirect.github.io/hbc-tech-blog/assets/js/vendor/scrollmagic/ScrollMagic.min.js"></script><script type="text/javascript" src="https://saksdirect.github.io/hbc-tech-blog/assets/js/vendor/jekyll-search-js/fetch.js"></script><script type="text/javascript" src="https://saksdirect.github.io/hbc-tech-blog/assets/js/vendor/jekyll-search-js/search.js"></script><script type="text/javascript" src="https://saksdirect.github.io/hbc-tech-blog/assets/js/main.js"></script></body></html>